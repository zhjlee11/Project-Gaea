{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QszWw_SYtgqw"
   },
   "source": [
    "# < Project Gaea 인공 신경망 >\n",
    "\n",
    "Project Gaea에서 핵심 역할을 하는 인공 신경망 학습 코드입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXqaVdkMt5W9"
   },
   "source": [
    "## (1) import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "asld2KUoawjz"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import keras\n",
    "\n",
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "keras.backend.backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from IPython.display import clear_output\n",
    "from skimage.transform import pyramid_expand\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CbTEt448b4R"
   },
   "outputs": [],
   "source": [
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "BATCH_SIZE = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가1. 하이퍼 파라미터 튜닝 변수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_1 = hp.HParam('g_1', hp.Discrete([32, 64, 128, 256, 512]))\n",
    "g_2 = hp.HParam('g_2', hp.Discrete([32, 64, 128, 256, 512]))\n",
    "g_3 = hp.HParam('g_3', hp.Discrete([32, 64, 128, 256, 512]))\n",
    "g_4 = hp.HParam('g_4', hp.Discrete([32, 64, 128, 256, 512]))\n",
    "g_5 = hp.HParam('g_5', hp.Discrete([32, 64, 128, 256, 512]))\n",
    "g_6 = hp.HParam('g_6', hp.Discrete([32, 64, 128, 256, 512]))\n",
    "g_7 = hp.HParam('g_7', hp.Discrete([32, 64, 128, 256, 512]))\n",
    "g_8 = hp.HParam('g_8', hp.Discrete([32, 64, 128, 256, 512]))\n",
    "g_9 = hp.HParam('g_9', hp.Discrete([32, 64, 128, 256, 512]))\n",
    "g_10 = hp.HParam('g_10', hp.Discrete([32, 64, 128, 256, 512]))\n",
    "g_11 = hp.HParam('g_11', hp.Discrete([32, 64, 128, 256, 512]))\n",
    "g_12 = hp.HParam('g_12', hp.Discrete([32, 64, 128, 256, 512]))\n",
    "g_13 =  hp.HParam('g_13', hp.Discrete([32, 64, 128, 256, 512]))\n",
    "g_14 = hp.HParam('g_14', hp.Discrete([32, 64, 128, 256, 512]))\n",
    "g_15 = hp.HParam('g_15', hp.Discrete([32, 64, 128, 256, 512]))\n",
    "g_k = hp.HParam('g_k', hp.Discrete([4, 9, 16]))\n",
    "\n",
    "d_1 = hp.HParam('d_1', hp.Discrete([32, 64, 128, 256, 512]))\n",
    "d_2 = hp.HParam('d_2', hp.Discrete([32, 64, 128, 256, 512]))\n",
    "d_3 = hp.HParam('d_3', hp.Discrete([32, 64, 128, 256, 512]))\n",
    "d_4 = hp.HParam('d_4', hp.Discrete([32, 64, 128, 256, 512]))\n",
    "d_k = hp.HParam('d_k', hp.Discrete([4, 9, 16]))\n",
    "\n",
    "HP_learning_rate = hp.HParam('learning_rate', hp.Discrete([0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.0]))\n",
    "HP_lamda = hp.HParam('lamda', hp.Discrete([1, 10, 50, 100, 125, 150]))\n",
    "HP_dropout = hp.HParam('dropout', hp.Discrete([0.0, 0.1, 0.2, 0.3, 0.4, 0.5]))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer('logs').as_default():\n",
    "    hp.hparams_config(\n",
    "    hparams=[g_1, g_2, g_3, g_4, g_5,g_6,g_7,g_8,g_9,g_10,g_11,g_12,g_13,g_14,g_15,g_k,d_1,d_2,d_3,d_4,d_k,HP_learning_rate,HP_lamda, HP_dropout],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')]\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCfxfSZPvB2C"
   },
   "source": [
    "## (2) 데이터셋 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yn3IwqhiIszt"
   },
   "outputs": [],
   "source": [
    "#이미지 주어진 크기에 따라 랜덤으로 분할,\n",
    "def random_crop(image, c=3):\n",
    "  cropped_image = tf.image.random_crop(\n",
    "      image, size=[IMG_HEIGHT, IMG_WIDTH, c])\n",
    "\n",
    "  return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "muhR2cgbLKWW"
   },
   "outputs": [],
   "source": [
    "# \"-1 <= image <= 1\" 로 변환\n",
    "def normalize(image):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = (image / 127.5) - 1\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVQOjcPVLrUc"
   },
   "outputs": [],
   "source": [
    "#이미지 변환 처리 중..\n",
    "def random_jitter(image, c=3):\n",
    "  # resizing to 286 x 286 x 3\n",
    "  image = tf.image.resize(image, [256, 256], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "  # randomly cropping to 256 x 256 x 3\n",
    "  image = random_crop(image, c=c)\n",
    "\n",
    "  # random mirroring\n",
    "  #image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tyaP4hLJ8b4W"
   },
   "outputs": [],
   "source": [
    "def preprocess_image_train(image, label):\n",
    "  image = random_jitter(image)\n",
    "  image = normalize(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VB3Z6D_zKSru"
   },
   "outputs": [],
   "source": [
    "def preprocess_image_test(image, label):\n",
    "  image = normalize(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VB3Z6D_zKSru"
   },
   "outputs": [],
   "source": [
    "def preprocess_image_test_nl(image):\n",
    "  image = normalize(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t_2LO0WPvMDd"
   },
   "outputs": [],
   "source": [
    "def preprocess_image_train_nl(image, c=3):\n",
    "  image = random_jitter(image, c=c)\n",
    "  image = normalize(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(n1, n2, d=0):\n",
    "    sn = abs(n1-n2)\n",
    "    if sn >= 0 and sn <= d :\n",
    "        return True\n",
    "    else :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B6TIIeOxudtj"
   },
   "outputs": [],
   "source": [
    "class imagedata:\n",
    "  def __init__(self, path,  w = 128, h = 192, degree=0):\n",
    "    self.degree=degree\n",
    "    self.outp = Image.open(path).convert(\"RGBA\")\n",
    "    \n",
    "    pix = np.array(self.outp)[0][0]\n",
    "    img = self.outp\n",
    "    datas = img.getdata()\n",
    "    newData = []\n",
    "    for item in datas:\n",
    "        if similar(item[0], pix[0], d=self.degree) and similar(item[1], pix[1], d=self.degree) and similar(item[2], pix[2], d=self.degree):\n",
    "            newData.append((255, 255, 255, 0))\n",
    "        else:\n",
    "            newData.append(item)\n",
    "    img.putdata(newData)\n",
    "    self.outp = img\n",
    "    \n",
    "    \n",
    "    \n",
    "    self.outp = img.resize((w, h))\n",
    "    area = (0, 0, int(w/4), int(h/4))\n",
    "    self.inp = self.outp.crop(area)\n",
    "    \n",
    "    inp1 = np.array(self.inp)\n",
    "    inp1 = cv2.cvtColor(inp1, cv2.COLOR_RGB2RGBA)\n",
    "    inp2 = cv2.vconcat([inp1, inp1, inp1, inp1])\n",
    "    self.inp = cv2.hconcat([inp2, inp2, inp2, inp2]) \n",
    "    \n",
    "    self.outp = np.array(img)\n",
    "    self.outp = cv2.cvtColor(self.outp, cv2.COLOR_RGB2RGBA)\n",
    "    \n",
    "   # print(\"인풋 사이즈 : \" + str(self.inp.shape))\n",
    "    #print(\"아웃풋 사이즈 : \" + str(self.outp.shape))\n",
    "    \n",
    "    self.inp = preprocess_image_train_nl(self.inp, c=4)\n",
    "    self.outp = preprocess_image_train_nl(self.outp, c=4)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6RDz38oCu3d9"
   },
   "outputs": [],
   "source": [
    "'''PATH_DIR='./Dataset/'\n",
    "filelist = []\n",
    "\n",
    "for i in [file for file in os.listdir(PATH_DIR) if file.endswith(\".png\") or file.endswith(\".jpg\") or file.endswith(\".jpge\") or file.endswith(\".bmp\")]:\n",
    "  try :\n",
    "    filelist.append(imagedata(PATH_DIR + str(i)))\n",
    "  except :\n",
    "    print(str(i)+\" 파일 로드 실패\")\n",
    "    continue\n",
    "  print(str(i)+\" 파일 로드 완료\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DIR='./Dataset/'\n",
    "filelist = [file for file in os.listdir(PATH_DIR) if file.endswith(\".png\") or file.endswith(\".jpg\") or file.endswith(\".jpge\") or file.endswith(\".bmp\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PcHckCev_UM"
   },
   "source": [
    "## (3) Pix2Pix 신경망 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "  if apply_batchnorm:\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(filters, size, hparams, apply_dropout=False):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "  result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  if apply_dropout:\n",
    "      result.add(tf.keras.layers.Dropout(hparams[HP_dropout]))\n",
    "\n",
    "  result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator(hparams):\n",
    "  inputs = tf.keras.layers.Input(shape=[256,256,4])\n",
    "\n",
    "  down_stack = [\n",
    "    downsample(hparams[g_1], hparams[g_k], apply_batchnorm=False), # (bs, 128, 128, 64)\n",
    "    downsample(hparams[g_2], hparams[g_k]), # (bs, 64, 64, 128)\n",
    "    downsample(hparams[g_3], hparams[g_k]), # (bs, 32, 32, 256)\n",
    "    downsample(hparams[g_4], hparams[g_k]), # (bs, 16, 16, 512)\n",
    "    downsample(hparams[g_5],hparams[g_k]), # (bs, 8, 8, 512)\n",
    "    downsample(hparams[g_6],hparams[g_k]), # (bs,hparams[g_k],hparams[g_k], 512)\n",
    "    downsample(hparams[g_7],hparams[g_k]), # (bs, 2, 2, 512)\n",
    "    downsample(hparams[g_8],hparams[g_k]), # (bs, 1, 1, 512)\n",
    "  ]\n",
    "\n",
    "  up_stack = [\n",
    "    upsample(hparams[g_9],hparams[g_k], hparams, apply_dropout=True), # (bs, 2, 2, 1024)\n",
    "    upsample(hparams[g_10],hparams[g_k], hparams, apply_dropout=True), # (bs,hparams[g_k],hparams[g_k], 1024)\n",
    "    upsample(hparams[g_11],hparams[g_k], hparams, apply_dropout=True), # (bs, 8, 8, 1024)\n",
    "    upsample(hparams[g_12],hparams[g_k], hparams), # (bs, 16, 16, 1024)\n",
    "    upsample(hparams[g_13],hparams[g_k], hparams), # (bs, 32, 32, 512)\n",
    "    upsample(hparams[g_14],hparams[g_k], hparams), # (bs, 64, 64, 256)\n",
    "    upsample(hparams[g_15],hparams[g_k], hparams), # (bs, 128, 128, 128)\n",
    "  ]\n",
    "\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "  last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS,hparams[g_k],\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation='tanh') # (bs, 256, 256, 3)\n",
    "\n",
    "  x = inputs\n",
    "\n",
    "  # Downsampling through the model\n",
    "  skips = []\n",
    "  for down in down_stack:\n",
    "    x = down(x)\n",
    "    skips.append(x)\n",
    "\n",
    "  skips = reversed(skips[:-1])\n",
    "\n",
    "  # Upsampling and establishing the skip connections\n",
    "  for up, skip in zip(up_stack, skips):\n",
    "    x = up(x)\n",
    "    x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "  x = last(x)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "  # mean absolute error\n",
    "  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "\n",
    "  return total_gen_loss, gan_loss, l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator(hparams):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  inp = tf.keras.layers.Input(shape=[256, 256, 4], name='input_image')\n",
    "  tar = tf.keras.layers.Input(shape=[256, 256, 4], name='target_image')\n",
    "\n",
    "  x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, channels*2)\n",
    "\n",
    "  down1 = downsample(hparams[d_1], hparams[d_k], False)(x) # (bs, 128, 128, 64)\n",
    "  down2 = downsample(hparams[d_2], hparams[d_k])(down1) # (bs, 64, 64, 128)\n",
    "  down3 = downsample(hparams[d_3], hparams[d_k])(down2) # (bs, 32, 32, 256)\n",
    "\n",
    "  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
    "  conv = tf.keras.layers.Conv2D(hparams[d_4], hparams[d_k], strides=1,\n",
    "                                kernel_initializer=initializer,\n",
    "                                use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
    "\n",
    "  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
    "\n",
    "  last = tf.keras.layers.Conv2D(1, hparams[d_k], strides=1,\n",
    "                                kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inp, tar], outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "  total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "  return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) 학습 Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NS2GWywBbAWo"
   },
   "outputs": [],
   "source": [
    "#학습 횟수\n",
    "EPOCHS = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "#이미지를 Generator을 통해서 \"여름->겨울\"로 변환하는 함수\n",
    "def generate_images(model, test_input):\n",
    "  prediction = model(test_input[np.newaxis], training=True)\n",
    "  test_input1 = cv2.resize(test_input[np.newaxis][0], dsize=(128, 192), interpolation=cv2.INTER_AREA)\n",
    "  prediction1 = cv2.resize(np.array(prediction[0]), dsize=(128, 192), interpolation=cv2.INTER_AREA)\n",
    "  plt.figure(figsize=(12, 12))\n",
    "\n",
    "\n",
    "  display_list = [test_input1, prediction1]\n",
    "  title = ['Input Image', 'Predicted Image']\n",
    "  for i in range(2):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.title(title[i])\n",
    "    # getting the pixel values between [0, 1] to plot it.\n",
    "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "    plt.axis('off')\n",
    "  \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rGfTUkLXgpYW"
   },
   "outputs": [],
   "source": [
    "#이미지를 Generator을 통해서 \"여름->겨울\"로 변환하는 함수\n",
    "def generate_images_r(model, test_input, real_output, e=-1):\n",
    "  prediction = model(test_input[np.newaxis], training=True)\n",
    "  test_input1 = cv2.resize(test_input[np.newaxis][0], dsize=(128, 192), interpolation=cv2.INTER_AREA)\n",
    "  prediction1 = cv2.resize(np.array(prediction[0]), dsize=(128, 192), interpolation=cv2.INTER_AREA)\n",
    "  plt.figure(figsize=(12, 12))\n",
    "\n",
    "\n",
    "  real_output1 = cv2.resize(real_output[np.newaxis][0], dsize=(128, 192), interpolation=cv2.INTER_AREA)\n",
    "  display_list = [test_input1, prediction1, real_output1]\n",
    "  title = ['Input Image', 'Predicted Image', 'Real Image']\n",
    "  for i in range(3):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.title(title[i])\n",
    "    # getting the pixel values between [0, 1] to plot it.\n",
    "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "    plt.axis('off')\n",
    "  \n",
    "  if e > -1 :\n",
    "    plt.savefig('genimage/Gen{0}.png'.format(e))\n",
    "  plt.show()\n",
    "  return prediction1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0s6lYKsD7m7m"
   },
   "outputs": [],
   "source": [
    "def sampling(train_x, train_y, batch_size) :\n",
    "  train_xb = np.empty(shape=[0, IMG_HEIGHT, IMG_WIDTH, 3], dtype='float32')\n",
    "  train_yb = np.empty(shape=[0, IMG_HEIGHT, IMG_WIDTH, 3], dtype='float32')\n",
    "  listaa = np.arange(train_x.shape[0])\n",
    "  listaa = np.random.choice(listaa, batch_size, replace=False)\n",
    "  for i in listaa:\n",
    "    train_xb = np.append(train_xb, train_x[i][np.newaxis], axis=0)\n",
    "    train_yb = np.append(train_yb, train_y[i][np.newaxis], axis=0)\n",
    "  return train_xb, train_yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBKUV2sKXDbY"
   },
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def train_step(input_image, target):\n",
    "  global generator, discriminator, generator_gradients, discriminator_gradients\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    gen_output = generator(input_image, training=True)\n",
    "\n",
    "    disc_real_output = discriminator([input_image, target], training=True)\n",
    "    disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "  generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                          generator.trainable_variables)\n",
    "  discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                               discriminator.trainable_variables)\n",
    "\n",
    "  generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                          generator.trainable_variables))\n",
    "  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                              discriminator.trainable_variables))\n",
    "    \n",
    "  return gen_total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWjQvnZA0kG2"
   },
   "source": [
    "## (7) 학습 함수 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def cal_g_loss(input_image, target, generator, discriminator):\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    gen_output = generator(input_image, training=True)\n",
    "\n",
    "    disc_real_output = discriminator([input_image, target], training=True)\n",
    "    disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "    \n",
    "  return gen_total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "def cal_d_loss(input_image, target, generator, discriminator):\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    gen_output = generator(input_image, training=True)\n",
    "\n",
    "    disc_real_output = discriminator([input_image, target], training=True)\n",
    "    disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "\n",
    "    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
    "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "    \n",
    "  return disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jY_8lH3mMUTT"
   },
   "outputs": [],
   "source": [
    "'''train_x = []\n",
    "train_y = []\n",
    "\n",
    "for i in filelist:\n",
    "  print(\"인풋 배열 크기 : \" + str(i.inp.shape))\n",
    "  print(\"아웃풋 배열 크기\" + str(i.outp.shape))\n",
    "  train_x.append(i.inp)\n",
    "  train_y.append(i.outp)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "import random\n",
    "def sampling_list(a, b, batch):\n",
    "  batches = [random.randint(0,len(a)-1) for r in range(0, batch)]\n",
    "  c = []\n",
    "  d = []\n",
    "  for j in batches:\n",
    "    c.append(a[j])\n",
    "    d.append(b[j])\n",
    "  g = np.empty(shape=[0, IMG_HEIGHT, IMG_WIDTH, 4], dtype='float32')\n",
    "  h = np.empty(shape=[0, IMG_HEIGHT, IMG_WIDTH, 4], dtype='float32')\n",
    "  for i in range(0, batch):\n",
    "    g = np.append(g, c[i][np.newaxis], axis=0)\n",
    "    h = np.append(h, d[i][np.newaxis], axis=0)\n",
    "  return g, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "#filelist.append(imagedata(PATH_DIR + str(i)))\n",
    "def sampling_batch(fl, b, pd='./Dataset/'):\n",
    "    while True :\n",
    "        try :\n",
    "            \n",
    "            g = np.empty(shape=[0, IMG_HEIGHT, IMG_WIDTH, 4], dtype='float32')\n",
    "            h = np.empty(shape=[0, IMG_HEIGHT, IMG_WIDTH, 4], dtype='float32')\n",
    "            for i in sample(fl,b):\n",
    "                g = np.append(g, imagedata(pd+str(i)).inp[np.newaxis], axis=0)\n",
    "                h = np.append(h, imagedata(pd+str(i)).outp[np.newaxis], axis=0)\n",
    "            return g, h\n",
    "        except :\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ugBkfCleSqv"
   },
   "outputs": [],
   "source": [
    "'''train_x = np.empty(shape=[0, IMG_HEIGHT, IMG_WIDTH, 3], dtype='float32')\n",
    "train_y = np.empty(shape=[0, IMG_HEIGHT, IMG_WIDTH, 3], dtype='float32')\n",
    "\n",
    "numi = 1\n",
    "for i in filelist:\n",
    "  #print(\"인풋 배열 크기 : \" + str(i.inp.shape))\n",
    "  #print(\"아웃풋 배열 크기\" + str(i.outp.shape))\n",
    "  #train_x.append(i.inp)\n",
    "  print(str(numi) + \"번째 이미지 로드 중..\")\n",
    "  \n",
    "  train_x = np.append(train_x, i.inp[np.newaxis], axis=0)\n",
    "  train_y = np.append(train_y, i.outp[np.newaxis], axis=0)\n",
    "  \n",
    "  if train_x.shape[0] % 500 == 0 and train_y.shape[0] % 500 == 0:\n",
    "    print(\"================================================================================================================\")\n",
    "    np.save(\"saved_array/train_x\", train_x)\n",
    "    np.save(\"saved_array/train_y\", train_y)\n",
    "    f = open(\"saved_array/textnum.txt\", 'w')\n",
    "    f.write(str(numi))\n",
    "    f.close()\n",
    "    \n",
    "    print(\"= \"+str(numi)+\"번쨰 배열 파일 세이브 완료\")\n",
    "    print(\"================================================================================================================\")\n",
    "  numi = numi + 1\n",
    "  #train_y.append(i.outp)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readago():\n",
    "    f = open(\"saved_loss/textnum5.txt\", \"r\")\n",
    "    lines = f.read()\n",
    "    f.close()\n",
    "    losstrainlist = []\n",
    "    losstestlist = []\n",
    "    for i in lines.split(\"\\n\"):\n",
    "        if i == \"[losslog]\" :\n",
    "            continue\n",
    "        losstrainlist.append(float(i.split(\":\")[1]))\n",
    "        losstestlist.append(float(i.split(\":\")[2]))\n",
    "        \n",
    "    return losstrainlist, losstestlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawlossg(ll1, ll2, epoch):\n",
    "    y1 = ll1\n",
    "    x1 = range(1, len(ll1)+1)\n",
    "    y2 = ll2\n",
    "    x2 = range(1, len(ll2)+1)\n",
    "    \n",
    "    plt.plot(x1, y1, x2, y2)\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.title(\"Loss Graph (Learning : {0})\".format(epoch))\n",
    "    plt.legend(['Train', 'Test'], loc=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveloss(epoch, loss1, loss2):\n",
    "    f = open(\"saved_loss/textnum5.txt\", \"a\")\n",
    "    f.write(\"\\n{0}:{1}:{2}\".format(str(epoch), str(loss1.numpy()), str(loss2.numpy())))\n",
    "    f.close()\n",
    "    return loss1.numpy(), loss2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH_DIR='./testinput/'\n",
    "testlist = []\n",
    "inputlist=[file for file in os.listdir(PATH_DIR) if file.endswith(\".png\") or file.endswith(\".jpg\") or file.endswith(\".jpge\") or file.endswith(\".bmp\")]\n",
    "for i in [file for file in os.listdir(PATH_DIR) if file.endswith(\".png\") or file.endswith(\".jpg\") or file.endswith(\".jpge\") or file.endswith(\".bmp\")]:\n",
    "  if i in filelist :\n",
    "    print(str(i)+\" 파일  Load fail\")\n",
    "    continue\n",
    "  try :\n",
    "    testlist.append(imagedata(PATH_DIR + str(i)))\n",
    "  except :\n",
    "    print(str(i)+\" 파일 로드 실패\")\n",
    "    continue\n",
    "  print(str(i)+\" 파일 로드 완료\")\n",
    "\n",
    "test_x = []\n",
    "test_y = []\n",
    "for i in testlist:\n",
    "  test_x.append(i.inp)\n",
    "  test_y.append(i.outp)\n",
    "#clear_output(wait=True)\n",
    "print(\"모든 테스트 이미지 로드 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(generator, discriminator, num):\n",
    "  generator.save('saved_model1/generator{0}.h5'.format(num))\n",
    "  discriminator.save('saved_model1/discriminator{0}.h5'.format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QPuS7pd24Q9z"
   },
   "outputs": [],
   "source": [
    "\n",
    "a, b= sampling_batch(filelist, BATCH_SIZE)\n",
    "print(\"학습 인풋의 형태 {0}\".format(a.shape))\n",
    "print(\"학습 아웃풋의 형태 {0}\".format(b.shape))\n",
    "plt.figure(figsize=(12, 12))\n",
    "cv2.imwrite('gradient/testx.png', (a[0]*0.5+0.5)*255)\n",
    "cv2.imwrite('gradient/testy.png', (b[0]*0.5+0.5)*255)\n",
    "\n",
    "display_list = [a[0], b[0]]\n",
    "title = ['Input Image', 'Output Image']\n",
    "for i in range(2):\n",
    "  plt.subplot(1, 2, i+1)\n",
    "  plt.title(title[i])\n",
    "  plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "  plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(arg):\n",
    "  arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n",
    "  return arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testall(ge, di):\n",
    "    PATH_DIR='./testinput2/'\n",
    "    testlist2 = []\n",
    "    inputlist=[file for file in os.listdir(PATH_DIR) if file.endswith(\".png\") or file.endswith(\".PNG\") or file.endswith(\".jpg\") or file.endswith(\".jpge\") or file.endswith(\".bmp\")]\n",
    "    for i in [file for file in os.listdir(PATH_DIR) if file.endswith(\".png\") or file.endswith(\".PNG\") or file.endswith(\".jpg\") or file.endswith(\".jpge\") or file.endswith(\".bmp\")]:\n",
    "      if i in filelist :\n",
    "        print(str(i)+\" 파일  Load fail\")\n",
    "        continue\n",
    "      try :\n",
    "        testlist2.append(imagedata(PATH_DIR + str(i)))\n",
    "      except :\n",
    "        print(str(i)+\" 파일 로드 실패\")\n",
    "        continue\n",
    "      #print(str(i)+\" 파일 로드 완료\")\n",
    "\n",
    "    test_x2 = []\n",
    "    test_y2 = []\n",
    "    for i in testlist2:\n",
    "      test_x2.append(i.inp)\n",
    "      test_y2.append(i.outp)\n",
    "    #print(\"모든 테스트 이미지 로드 완료\")\n",
    "\n",
    "    c, d = sampling_list(test_x2, test_y2, 3)\n",
    "\n",
    "    model = generator #tf.keras.models.load_model(\"saved_model/generator4.h5\")\n",
    "    #cv2.imwrite('rinptt.png', (cv2.cvtColor(np.array(testlist2[1].inp), cv2.COLOR_BGR2RGBA)*0.5+0.5)*255)\n",
    "    \n",
    "    ct1 = c[0][np.newaxis]\n",
    "    ct2 = c[1][np.newaxis]\n",
    "    ct3 = c[2][np.newaxis]\n",
    "    \n",
    "    dt1 = d[0][np.newaxis]\n",
    "    dt2 = d[1][np.newaxis]\n",
    "    dt3 = d[2][np.newaxis]\n",
    "    \n",
    "    lossg = 0.0\n",
    "    lossg+=cal_g_loss(ct1, dt1, ge, di)\n",
    "    lossg+=cal_g_loss(ct2, dt2, ge, di)\n",
    "    lossg+=cal_g_loss(ct3, dt3, ge, di)\n",
    "    \n",
    "    lossd = 0.0\n",
    "    lossd+=cal_d_loss(ct1, dt1, ge, di)\n",
    "    lossd+=cal_d_loss(ct2, dt2, ge, di)\n",
    "    lossd+=cal_d_loss(ct3, dt3, ge, di)\n",
    "    \n",
    "    return lossg, lossd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "12kfQlsq1otX"
   },
   "source": [
    "## (8) 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2M7LmLtGEMQJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator = None\n",
    "discriminator = None\n",
    "generator_optimizer = None\n",
    "discriminator_optimizer = None\n",
    "\n",
    "def trainging(num, hparams):\n",
    "    global generator, discriminator, generator_optimizer, discriminator_optimizer\n",
    "    with tf.summary.create_file_writer('logs/'+str(num)).as_default():\n",
    "        generator = Generator(hparams)\n",
    "        discriminator = Discriminator(hparams)\n",
    "\n",
    "        generator_optimizer = tf.keras.optimizers.Adam(hparams[HP_learning_rate], beta_1=0.5)\n",
    "        discriminator_optimizer = tf.keras.optimizers.Adam(hparams[HP_learning_rate], beta_1=0.5)\n",
    "\n",
    "        for epoch in range(0, EPOCHS):\n",
    "          a, b = sampling_batch(filelist, BATCH_SIZE, pd='./Dataset/')\n",
    "          c, d = sampling_list(test_x, test_y, 1)\n",
    "          \n",
    "          for n in range(0, BATCH_SIZE):\n",
    "                xT = a[n][np.newaxis]\n",
    "                yT = b[n][np.newaxis]\n",
    "                losstrain = train_step(xT, yT)\n",
    "          if epoch%10 == 0:\n",
    "              print(\"[{0}번째 튜닝] {1}번째 학습 완료\".format(num, epoch))\n",
    "        \n",
    "        #save_model(generator, discriminator, num)\n",
    "        _lg, _ld = testall(generator, discriminator)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, _lg + _ld, step=1)\n",
    "        return _lg, _ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tunner():\n",
    "    def __init__(self, num, hp, gl, dl):\n",
    "        self.num = num\n",
    "        self.hp = hp\n",
    "        self.gl = gl\n",
    "        self.dl = dl\n",
    "        \n",
    "    def debug(self, doPrint=False):\n",
    "        msg = \"------------------------------ < {0}번째 튜너 > -------------------------\".format(self.num)\n",
    "        msg += \"\\n\"+str({h.name: self.hp[h] for h in self.hp})\n",
    "        msg += \"\\nGenerator Loss : {0}\".format(self.gl)\n",
    "        msg += \"\\nDiscriminator Loss : {0}\".format(self.dl)\n",
    "        msg += \"\\n----------------------------------------------------------------------\"\n",
    "        if doPrint == True:\n",
    "            print(msg)\n",
    "        return msg\n",
    "    \n",
    "    def savefile(self, dire='tunners'):\n",
    "        f = open('{0}/{1}.txt'.format(dire, self.num), 'w')\n",
    "        f.write(self.debug(doPrint=False))\n",
    "        f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunnerlist = {}\n",
    "session_num=0\n",
    "max_session=300\n",
    "for _ in range(max_session):\n",
    "    hparams = {\n",
    "        g_1: random.choice(g_1.domain.values),\n",
    "        g_2: random.choice(g_2.domain.values),\n",
    "        g_3: random.choice(g_3.domain.values),\n",
    "        g_4: random.choice(g_4.domain.values),\n",
    "        g_5: random.choice(g_5.domain.values),\n",
    "        g_6: random.choice(g_6.domain.values),\n",
    "        g_7: random.choice(g_7.domain.values),\n",
    "        g_8: random.choice(g_8.domain.values),\n",
    "        g_9: random.choice(g_9.domain.values),\n",
    "        g_10: random.choice(g_10.domain.values),\n",
    "        g_11: random.choice(g_11.domain.values),\n",
    "        g_12: random.choice(g_12.domain.values),\n",
    "        g_13: random.choice(g_13.domain.values),\n",
    "        g_14: random.choice(g_14.domain.values),\n",
    "        g_15: random.choice(g_15.domain.values),\n",
    "        g_k: random.choice(g_k.domain.values),\n",
    "        d_1: random.choice(d_1.domain.values),\n",
    "        d_2: random.choice(d_2.domain.values),\n",
    "        d_3: random.choice(d_3.domain.values),\n",
    "        d_4: random.choice(d_4.domain.values),\n",
    "        d_k: random.choice(d_k.domain.values),\n",
    "        HP_learning_rate: random.choice(HP_learning_rate.domain.values),\n",
    "        HP_lamda: random.choice(HP_lamda.domain.values),\n",
    "        HP_dropout: random.choice(HP_dropout.domain.values),\n",
    "    }\n",
    "    run_name = \"run-%d\" % session_num\n",
    "    print('--- Starting trial: %s' % run_name)\n",
    "    print({h.name: hparams[h] for h in hparams})\n",
    "    LAMBDA = hparams[HP_lamda]\n",
    "    _lg, _ld = trainging(session_num, hparams)\n",
    "    print(\"G 손실 : {0} & D 손실 : {1}\\n\\n\".format(_lg, _ld))\n",
    "    tunner(session_num, hparams, _lg, _ld).savefile()\n",
    "    tunnerlist[session_num] = tunner(session_num, hparams, _lg, _ld)\n",
    "    session_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kkMcHEQO1ruM"
   },
   "source": [
    "## (9) Model 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TW4sk_1wHZFA"
   },
   "outputs": [],
   "source": [
    "generator_g.save('saved_model/generator_g', save_format='tf')\n",
    "print(\"generator_g 저장 완료\")\n",
    "generator_f.save('saved_model/generator_f', save_format='tf')\n",
    "print(\"generator_f 저장 완료\")\n",
    "discriminator_x.save('saved_model/discriminator_x', save_format='tf')\n",
    "print(\"discriminator_x 저장 완료\")\n",
    "discriminator_y.save('saved_model/discriminator_y', save_format='tf')\n",
    "print(\"discriminator_y 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH_DIR='./testinput2/'\n",
    "testlist2 = []\n",
    "inputlist=[file for file in os.listdir(PATH_DIR) if file.endswith(\".png\") or file.endswith(\".PNG\") or file.endswith(\".jpg\") or file.endswith(\".jpge\") or file.endswith(\".bmp\")]\n",
    "for i in [file for file in os.listdir(PATH_DIR) if file.endswith(\".png\") or file.endswith(\".PNG\") or file.endswith(\".jpg\") or file.endswith(\".jpge\") or file.endswith(\".bmp\")]:\n",
    "  if i in filelist :\n",
    "    print(str(i)+\" 파일  Load fail\")\n",
    "    continue\n",
    "  try :\n",
    "    testlist2.append(imagedata(PATH_DIR + str(i)))\n",
    "  except :\n",
    "    print(str(i)+\" 파일 로드 실패\")\n",
    "    continue\n",
    "  print(str(i)+\" 파일 로드 완료\")\n",
    "\n",
    "test_x2 = []\n",
    "test_y2 = []\n",
    "for i in testlist2:\n",
    "  test_x2.append(i.inp)\n",
    "  test_y2.append(i.outp)\n",
    "print(\"모든 테스트 이미지 로드 완료\")\n",
    "\n",
    "c, d = sampling_list(test_x2, test_y2, 3)\n",
    "\n",
    "model = generator #tf.keras.models.load_model(\"saved_model/generator4.h5\")\n",
    "#cv2.imwrite('rinptt.png', (cv2.cvtColor(np.array(testlist2[1].inp), cv2.COLOR_BGR2RGBA)*0.5+0.5)*255)\n",
    "generate_images_r(model, c[0], d[0])\n",
    "generate_images_r(model, c[1], d[1])\n",
    "generate_images_r(model, c[2], d[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DIR='./testinput2/'\n",
    "testlist2 = []\n",
    "inputlist=[file for file in os.listdir(PATH_DIR) if file.endswith(\".png\") or file.endswith(\".PNG\") or file.endswith(\".jpg\") or file.endswith(\".jpge\") or file.endswith(\".bmp\")]\n",
    "for i in [file for file in os.listdir(PATH_DIR) if file.endswith(\".png\") or file.endswith(\".PNG\") or file.endswith(\".jpg\") or file.endswith(\".jpge\") or file.endswith(\".bmp\")]:\n",
    "  if i in filelist :\n",
    "    print(str(i)+\" 파일  Load fail\")\n",
    "    continue\n",
    "  try :\n",
    "    testlist2.append(imagedata(PATH_DIR + str(i)))\n",
    "  except :\n",
    "    print(str(i)+\" 파일 로드 실패\")\n",
    "    continue\n",
    "  print(str(i)+\" 파일 로드 완료\")\n",
    "\n",
    "test_x2 = []\n",
    "test_y2 = []\n",
    "for i in testlist2:\n",
    "  test_x2.append(i.inp)\n",
    "  test_y2.append(i.outp)\n",
    "print(\"모든 테스트 이미지 로드 완료\")\n",
    "\n",
    "c, d = sampling_list(test_x2, test_y2, 3)\n",
    "\n",
    "model = tf.keras.models.load_model(\"saved_model/1st save/generator4.h5\")\n",
    "#cv2.imwrite('rinptt.png', (cv2.cvtColor(np.array(testlist2[1].inp), cv2.COLOR_BGR2RGBA)*0.5+0.5)*255)\n",
    "generate_images_r(model, c[0], d[0])\n",
    "generate_images_r(model, c[1], d[1])\n",
    "generate_images_r(model, c[2], d[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('saved_model/generator_g')\n",
    "generate_images_r(model, train_x[0], train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('saved_model/generator_final.h5')\n",
    "discriminator.save('saved_model/discriminator_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the MobileNet tf.keras model.\n",
    "model = tf.keras.applications.MobileNetV2(\n",
    "    weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "\n",
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the TensorFlow Lite model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# Test the TensorFlow model on random input data.\n",
    "tf_results = model(tf.constant(input_data))\n",
    "\n",
    "# Compare the result.\n",
    "for tf_result, tflite_result in zip(tf_results, tflite_results):\n",
    "  np.testing.assert_almost_equal(tf_result, tflite_result, decimal=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cyclegan.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
