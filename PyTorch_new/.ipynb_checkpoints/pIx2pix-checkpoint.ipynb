{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_serVlngU4os"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torch.optim import *\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.utils as vutils\n",
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import random\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWKkKb2enQ34"
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "PATH = '/Dataset'\n",
    "PATH2 = '/models/'\n",
    "batch_size = 4\n",
    "lrG = 0.0002\n",
    "lrD = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "L1lambda = 100\n",
    "num_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zu0YJpnf8wcc"
   },
   "outputs": [],
   "source": [
    "transform = albumentations.Compose([\n",
    "    albumentations.Resize(256, 256), \n",
    "    #albumentations.RandomCrop(224, 224),\n",
    "    #albumentations.HorizontalFlip(), # Same with transforms.RandomHorizontalFlip()\n",
    "    albumentations.pytorch.transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJK1LwVSbvEQ"
   },
   "outputs": [],
   "source": [
    "#import glob\n",
    "#import cv2 as cv\n",
    "#path = glob.glob(\"/path/to/folder/*.jpg\")\n",
    "#cv_img = []\n",
    "#for img in path:\n",
    "#    n = cv.imread(img)\n",
    "#    cv_img.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j33jYGvKYDKi"
   },
   "outputs": [],
   "source": [
    "onlyfiles = [file for file in glob.glob(os.getcwd()+PATH+\"/*\") if file.endswith('.png') or file.endswith('.PNG')]\n",
    "images = np.empty(len(onlyfiles), dtype=object)\n",
    "for n in range(0, len(onlyfiles)):\n",
    "  images[n] = cv2.imread( join(PATH, onlyfiles[n]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "93UhAU3x80yI"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, file, transform=None):\n",
    "        self.file = file\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.file[idx]\n",
    "        sketch_image = cv2.cvtColor(img[:,:256,:], cv2.COLOR_BGR2RGBA)\n",
    "        real_image = cv2.cvtColor(img[:,256:,:], cv2.COLOR_BGR2RGBA)\n",
    "        if self.transform:\n",
    "            augmented1 = self.transform(image=sketch_image) \n",
    "            image1 = augmented1['image']\n",
    "            augmented2 = self.transform(image= real_image) \n",
    "            image2 = augmented2['image']\n",
    "        return image1, image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rxEiBXImGGOg"
   },
   "outputs": [],
   "source": [
    "dataset = CustomDataset(images, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MGALbpATpaE"
   },
   "outputs": [],
   "source": [
    "dataloader =DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HfEpCVHpxsF-"
   },
   "outputs": [],
   "source": [
    "# U-net 구조를 만들어보자\n",
    "\n",
    "class Generator(nn.Module):\n",
    "  def __init__(self, ngf=64): ### Question -> why self.conv_bn no?\n",
    "    super(Generator, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(4, ngf, kernel_size=4, stride=2, padding=1) #(3, 256, 256)->(64, 128, 128)\n",
    "    self.conv2 = nn.Conv2d(ngf, ngf*2, 4, 2, 1) #(64, 128, 128)->(128, 64, 64)\n",
    "    self.conv2_bn = nn.BatchNorm2d(ngf*2) \n",
    "    self.conv3 = nn.Conv2d(ngf*2, ngf*4, 4, 2, 1) #(128, 64, 64)->(256, 32, 32)\n",
    "    self.conv3_bn = nn.BatchNorm2d(ngf*4) \n",
    "    self.conv4 = nn.Conv2d(ngf*4, ngf*8, 4, 2, 1) #(256, 32, 32)->(512, 16, 16)\n",
    "    self.conv4_bn = nn.BatchNorm2d(ngf*8) \n",
    "    self.conv5 = nn.Conv2d(ngf*8, ngf*8, 4, 2, 1) #(512, 16, 16)->(512, 8, 8)\n",
    "    self.conv5_bn = nn.BatchNorm2d(ngf*8) \n",
    "    self.conv6 = nn.Conv2d(ngf*8, ngf*8, 4, 2, 1) #(512, 8, 8)->(512, 4, 4)\n",
    "    self.conv6_bn = nn.BatchNorm2d(ngf*8) \n",
    "    self.conv7 = nn.Conv2d(ngf*8, ngf*8, 4, 2, 1) #(512, 4, 4)->(512, 2, 2)\n",
    "    self.conv7_bn = nn.BatchNorm2d(ngf*8) \n",
    "    self.conv8 = nn.Conv2d(ngf*8, ngf*8, 4, 2, 1) #(512, 2, 2)->(512, 1, 1)\n",
    "    self.conv8_bn = nn.BatchNorm2d(ngf*8) \n",
    "\n",
    "    self.deconv0 = nn.ConvTranspose2d(ngf*8, ngf*8, 4, 2, 1) #(512, 1, 1)->(512, 2, 2)  # concat 했으니까 수정해야함\n",
    "    self.deconv0_bn = nn.BatchNorm2d(ngf*8) \n",
    "    self.deconv1 = nn.ConvTranspose2d(ngf*8*2, ngf*8, 4, 2, 1) #(512, 2, 2)->(512, 4, 4)\n",
    "    self.deconv1_bn = nn.BatchNorm2d(ngf*8) \n",
    "    self.deconv2 = nn.ConvTranspose2d(ngf*8*2, ngf*8, 4, 2, 1) #(512, 4, 4)->(512, 8, 8)\n",
    "    self.deconv2_bn = nn.BatchNorm2d(ngf*8) \n",
    "    self.deconv3 = nn.ConvTranspose2d(ngf*8*2, ngf*8, 4, 2, 1) #(512, 8, 8)->(512, 16, 16)\n",
    "    self.deconv3_bn = nn.BatchNorm2d(ngf*8) \n",
    "    self.deconv4 = nn.ConvTranspose2d(ngf*8*2, ngf*4, 4, 2, 1) #(512, 16, 16)->(256, 32, 32)\n",
    "    self.deconv4_bn = nn.BatchNorm2d(ngf*4) \n",
    "    self.deconv5 = nn.ConvTranspose2d(ngf*4*2, ngf*2, 4, 2, 1) #(256, 32, 32)->(128, 64, 64)\n",
    "    self.deconv5_bn = nn.BatchNorm2d(ngf*2) \n",
    "    self.deconv6 = nn.ConvTranspose2d(ngf*2*2, ngf, 4, 2, 1) #(128, 64, 64)->(64, 128, 128)\n",
    "    self.deconv6_bn = nn.BatchNorm2d(ngf) \n",
    "    self.deconv7 = nn.ConvTranspose2d(ngf*2, 4, 4, 2, 1) #(64, 128, 128)->(3, 256, 256)\n",
    "\n",
    "    self.leaky = nn.LeakyReLU(0.2, True)\n",
    "    self.relu = nn.ReLU(True)\n",
    "    self.drop = nn.Dropout(0.5)\n",
    "\n",
    "  def forward(self, input): # (3, 256, 256) <- input\n",
    "    x1 = self.conv1(input) #(64, 128, 128)<- x1\n",
    "\n",
    "    x2 = self.leaky(x1)\n",
    "    x2 = self.conv2(x1)\n",
    "    x2 = self.conv2_bn(x2)\n",
    "\n",
    "    x3 = self.leaky(x2)   \n",
    "    x3 = self.conv3(x3)\n",
    "    x3 = self.conv3_bn(x3)\n",
    "\n",
    "    x4 = self.leaky(x3)  \n",
    "    x4 = self.conv4(x4)\n",
    "    x4 = self.conv4_bn(x4)  \n",
    "\n",
    "    x5 = self.leaky(x4)\n",
    "    x5 = self.conv5(x5)    \n",
    "    x5 = self.conv5_bn(x5)  \n",
    "\n",
    "    x6 = self.leaky(x5)\n",
    "    x6 = self.conv6(x6)    \n",
    "    x6 = self.conv6_bn(x6)\n",
    "\n",
    "    x7 = self.leaky(x6)\n",
    "    x7 = self.conv7(x7)\n",
    "    x7 = self.conv7_bn(x7)\n",
    "\n",
    "    x8 = self.leaky(x7)\n",
    "    x8 = self.conv8(x7)\n",
    "\n",
    "    y1 = self.relu(x8)\n",
    "    y1 = self.deconv0(y1)\n",
    "    y1 = self.deconv0_bn(y1)\n",
    "    y1 = self.drop(y1)\n",
    "    y1 = torch.cat([y1,x7], dim=1)\n",
    "\n",
    "    y2 = self.relu(y1)\n",
    "    y2 = self.deconv1(y2)\n",
    "    y2 = self.deconv1_bn(y2)\n",
    "    y2 = self.drop(y2)\n",
    "    y2 = torch.cat([y2,x6], dim=1)\n",
    "\n",
    "    y3 = self.relu(y2)\n",
    "    y3 = self.deconv2(y3)\n",
    "    y3 = self.deconv2_bn(y3)\n",
    "    y3 = self.drop(y3)\n",
    "    y3 = torch.cat([y3,x5], dim=1)\n",
    "\n",
    "    y4 = self.relu(y3)\n",
    "    y4 = self.deconv3(y4)\n",
    "    y4 = self.deconv3_bn(y4)\n",
    "    y4 = torch.cat([y4,x4], dim=1)\n",
    "\n",
    "    y5 = self.relu(y4)\n",
    "    y5 = self.deconv4(y5)\n",
    "    y5 = self.deconv4_bn(y5)\n",
    "    y5 = torch.cat([y5,x3], dim=1)\n",
    "\n",
    "    y6 = self.relu(y5)\n",
    "    y6 = self.deconv5(y6)\n",
    "    y6 = self.deconv5_bn(y6)\n",
    "    y6 = torch.cat([y6,x2], dim=1)\n",
    "\n",
    "    y7 = self.relu(y6)\n",
    "    y7 = self.deconv6(y7)\n",
    "    y7 = self.deconv6_bn(y7)\n",
    "    y7 = torch.cat([y7,x1], dim=1)\n",
    "\n",
    "    y8 = self.relu(y7)\n",
    "    y8 = self.deconv7(y8)\n",
    "\n",
    "    output = nn.Tanh()(y8)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jb0NK-X3RTpi"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module): # 70*70 Patch\n",
    "  def __init__(self, ndf=64):\n",
    "    super(Discriminator, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(8, ndf, 4, 2, 1) \n",
    "    self.conv2 = nn.Conv2d(ndf, ndf*2, 4, 2, 1)\n",
    "    self.conv2_bn = nn.BatchNorm2d(ndf*2)\n",
    "    self.conv3 = nn.Conv2d(ndf*2, ndf*4, 4, 2, 1)\n",
    "    self.conv3_bn = nn.BatchNorm2d(ndf*4)\n",
    "    self.conv4 = nn.Conv2d(ndf*4, ndf*8, 4, 1, 1)\n",
    "    self.conv4_bn = nn.BatchNorm2d(ndf*8)\n",
    "    self.conv5 = nn.Conv2d(ndf*8, 1, 4, 1, 1)\n",
    "\n",
    "    self.leaky = nn.LeakyReLU(0.2, True)\n",
    "\n",
    "  def forward(self, input, label):\n",
    "    x = torch.cat([input,label], dim=1)\n",
    "    x = self.conv1(x)\n",
    "    x = self.leaky(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.conv2_bn(x)\n",
    "    x = self.leaky(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.conv3_bn(x)\n",
    "    x = self.leaky(x)\n",
    "    x = self.conv4(x)\n",
    "    x = self.conv4_bn(x)\n",
    "    x = self.leaky(x)\n",
    "    x = self.conv5(x)\n",
    "    output = nn.Sigmoid()(x)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T0FfeViilBUM"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testpic():\n",
    "    onlyfilesT = [file for file in glob.glob(os.getcwd()+\"/TestDataset/*\") if file.endswith('.png') or file.endswith('.PNG')]\n",
    "    imagesT = np.empty(len(onlyfilesT), dtype=object)\n",
    "    print(onlyfilesT)\n",
    "    for n in range(0, len(onlyfilesT)):\n",
    "      imagesT[n] = cv2.imread(onlyfilesT[n])\n",
    "\n",
    "    dataloaderT = DataLoader(CustomDataset(imagesT, transform), batch_size=1, shuffle=True)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    num = 0\n",
    "    for i, data in enumerate(dataloaderT):\n",
    "        if(num>=1) :\n",
    "            break\n",
    "        num+=1\n",
    "        x = data[0]\n",
    "        y = data[1]\n",
    "\n",
    "        pic = netG(x)\n",
    "        pic = np.transpose(pic.detach().numpy()[0], (1, 2, 0))\n",
    "        #print(pic.shape)\n",
    "        plt.imshow(pic)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "colab_type": "code",
    "id": "ClOoR5aWm6Sh",
    "outputId": "a1299332-4aa4-4263-e762-9750235228ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (conv1): Conv2d(4, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv3_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv4_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv5_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv6): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv6_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv7): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv7_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv8): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv8_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (deconv0): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (deconv0_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (deconv1): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (deconv1_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (deconv2): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (deconv2_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (deconv3): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (deconv3_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (deconv4): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (deconv4_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (deconv5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (deconv5_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (deconv6): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (deconv6_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (deconv7): ConvTranspose2d(128, 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (leaky): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = Generator().to(device)\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "colab_type": "code",
    "id": "HpYMeis9nLIp",
    "outputId": "03fd961b-e293-4a50-977b-bcc6f44c08d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (conv1): Conv2d(8, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (conv3_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "  (leaky): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netD = Discriminator().to(device)\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mB6fYw_lNNMF"
   },
   "outputs": [],
   "source": [
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "img_list = []\n",
    "G_loss = []\n",
    "D_loss = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lvtBoVwR_GIk"
   },
   "outputs": [],
   "source": [
    "def fit(num_epochs=15):\n",
    "  print(\"Starting Training Loop...\")\n",
    "  optimizerG = Adam(netG.parameters(), lr=lrG, betas=(beta1, beta2))\n",
    "  optimizerD = Adam(netD.parameters(), lr=lrD, betas=(beta1, beta2))\n",
    "  iters = 0\n",
    "  for epoch in range(num_epochs):\n",
    "    print(f\"EPOCH{epoch+1}:\")\n",
    "    train_one_epoch(dataloader, netG, netD, optimizerG, optimizerD, epoch)\n",
    "\n",
    "\n",
    "def train_one_epoch(dataloader, netG, netD, optimizerG, optimizerD, epoch, iters=0):\n",
    "  for i, data in enumerate(dataloader):\n",
    "\n",
    "        netD.zero_grad()\n",
    "        sketch, real = data\n",
    "        sketch, real = sketch.to(device), real.to(device)\n",
    "        \n",
    "        D_real = netD(sketch, real).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        label = torch.full((D_real.size(0),), real_label, device=device)\n",
    "        errD_real = nn.BCELoss()(D_real, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = D_real.mean().item()\n",
    "      \n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(sketch)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        D_fake = netD(sketch, fake.detach()).view(-1)\n",
    "        \n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = nn.BCELoss()(D_fake, label)\n",
    "        # Calculate the gradients for this batch\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = D_fake.mean().item()\n",
    "        # Add the gradients from the all-real and all-fake batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        D_output = netD(sketch, fake).view(-1)\n",
    "        G_output = netG(sketch)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = nn.BCELoss()(D_output, label)+ nn.L1Loss()(G_output, real)*L1lambda\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = D_output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_loss.append(errG.item())\n",
    "        D_loss.append(errD.item())\n",
    "        \n",
    "        if(iters%100==0) :\n",
    "            testpic()\n",
    "\n",
    "        # Check how the generator is doing\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(sketch).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "colab_type": "code",
    "id": "cV8xouBfKHCe",
    "outputId": "e8123175-64ef-4724-d2a7-cbd3a20330c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "EPOCH1:\n",
      "[0/15][0/3]\tLoss_D: 1.7118\tLoss_G: 79.4221\tD(x): 0.3825\tD(G(z)): 0.3645 / 0.4645\n",
      "EPOCH2:\n",
      "[1/15][0/3]\tLoss_D: 1.2754\tLoss_G: 70.4430\tD(x): 0.6170\tD(G(z)): 0.4877 / 0.3964\n",
      "EPOCH3:\n",
      "[2/15][0/3]\tLoss_D: 0.9760\tLoss_G: 62.2135\tD(x): 0.6254\tD(G(z)): 0.3533 / 0.3101\n",
      "EPOCH4:\n",
      "[3/15][0/3]\tLoss_D: 0.9120\tLoss_G: 53.4814\tD(x): 0.6661\tD(G(z)): 0.3063 / 0.2780\n",
      "EPOCH5:\n",
      "[4/15][0/3]\tLoss_D: 0.5451\tLoss_G: 47.0552\tD(x): 0.7639\tD(G(z)): 0.2224 / 0.1659\n"
     ]
    }
   ],
   "source": [
    "fit(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X7d3cPz_IVdn"
   },
   "outputs": [],
   "source": [
    "torch.save(netG.state_dict(), 'G1.pth')\n",
    "torch.save(netD.state_dict(), 'D1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNAvYx3ZI+7kuAJGocIVAF+",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "pix2pix.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
